import os
import json
import time
from google import genai
from openai import OpenAI
from dotenv import load_dotenv

from rag_functions.pinecone_functions import query_db
from deepfake_functions.deepfake import detect_deepfake_video
from app.controllers._utils import get_json_from_string

with open(os.path.join("app", "data", "law_descriptions_bonitinho.json"), "r", encoding="utf8") as file:
    law_descriptions = json.load(file)
    
with open(os.path.join("app", "data", "law_personalized_prompts.json"), "r", encoding="utf8") as file:
    law_personalized_prompts = json.load(file)

load_dotenv()


def extrair_placa(mocked: bool = True, video_path: str = None,
                  attention_law_references: list = [], video_filename: str = None) -> list:
    # Google Gemini API Key
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEY n√£o definida no .env")

    # OpenAI API Key
    # client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    # if not client.api_key:
    #     raise ValueError("OPENAI_API_KEY n√£o definida no .env")

    # Inicializa cliente Gemini
    if not mocked:
        client = genai.Client(api_key=api_key)

        # video_path = "/Users/infra/Documents/Adapta Challenge/projeto/apiFlask/flaskapi/app/data/ultrapassagens16s.mp4"

        # Upload do v√≠deo
        if video_filename is None:
            video_file = client.files.upload(file=video_path)
            file_name = video_file.name
        else:
            file_name = video_filename
        
        
        # No need to verify deepfake for images that are already uploaded
        if video_filename is None and detect_deepfake_video(video_path) == "Fake":
            print("‚ö†Ô∏è V√≠deo detectado como Deepfake. An√°lise n√£o realizada.")
            return {"status": "error", "message": "V√≠deo detectado como Deepfake."}

        # Aguarda processamento
        while video_file.state.name == "PROCESSING":
            print("Aguardando processamento do v√≠deo...")
            time.sleep(2)
            video_file = client.files.get(name=file_name)

        # An√°lise com Gemini
        if attention_law_references == []:
            gemini_prompt = (
                "Gere uma descri√ß√£o do que aconteceu no v√≠deo. Leve em conta os detalhes, como de que forma "
                "a ultrapassagem foi feita, se era permitida naquele local (segundo sinaliza√ß√£o no piso, como faixa dupla cont√≠nua ou placa), "
                "e outros detalhes que possam ser importantes. Me d√™ tamb√©m a placa e modelo dos ve√≠culos identificados."
            )
        else:
            observations = "\n\n"
            
            for law_reference in attention_law_references:
                if law_reference in law_personalized_prompts:
                    observations += "- " + law_personalized_prompts[law_reference] + "\n"
                    
            gemini_prompt = (
                "Gere uma descri√ß√£o do que aconteceu no v√≠deo, levando em conta os detalhes, como de que forma "
                "a ultrapassagem foi feita, se era permitida naquele local (segundo sinaliza√ß√£o no piso, como faixa dupla cont√≠nua ou placa), "
                "e outros detalhes que possam ser importantes. Me d√™ tamb√©m a placa e modelo dos ve√≠culos identificados.\n\n"
                f"Observa√ß√µes para se atentar se ocorrem no v√≠deo ou n√£o:{observations}"
            )
        
        gemini_response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[gemini_prompt, video_file]
        )
        gemini_text = gemini_response.text
        
    else:
        print("\n\n****** ENTROU NO MOCKED *********\n\n")
        gemini_text = get_gemini_response_mock()

    
    print("üîç Resposta do Gemini:\n", gemini_text)

    print("\n\n***************************************************************\n\n")

    structured_output = interpretar_com_gpt(gemini_text=gemini_text, mock=False)
    
    retry_with_law_references, final_output = add_law_references(structured_output, 
     pre_law_references=attention_law_references)

    if len(retry_with_law_references) > 0:
        return extrair_placa(mocked=mocked, video_path=video_path, attention_law_references=retry_with_law_references, video_filename=video_filename)
    
    for idx, item in enumerate(final_output):
        if item['Poss√≠vel infra√ß√£o'] == "n√£o":
            item['Comportamento observado'] = item['Comportamento observado'].replace("comportamento observado", "comportamento observado")

    print("üìã An√°lise estruturada para infra√ß√µes:\n", final_output)

    print("\n\n***************************************************************\n\n")

    return final_output

def get_gemini_response_mock():
    return """"
    Com base no v√≠deo, segue a descri√ß√£o detalhada do ocorrido:

**Descri√ß√£o do Ocorrido:**

O v√≠deo √© gravado de uma c√¢mera posicionada no topo da cabine de um caminh√£o (aparentemente uma carreta), mostrando a perspectiva para frente. A pista est√° molhada, indicando que est√° chovendo ou choveu recentemente, e h√° spray de √°gua sendo levantado pelos ve√≠culos.

A rodovia √© de pista simples, com uma faixa em cada sentido. A sinaliza√ß√£o horizontal no asfalto √© de **faixa dupla cont√≠nua amarela**, indicando que a ultrapassagem √© proibida para ambos os sentidos de tr√°fego naquele trecho. Al√©m disso, a manobra ocorre em uma **curva**, o que agrava a situa√ß√£o de perigo e √© outro fator que, por si s√≥, pro√≠be a ultrapassagem segundo o C√≥digo de Tr√¢nsito Brasileiro (CTB).

Um ve√≠culo branco, um sedan, tenta realizar uma ultrapassagem arriscada. Ele sai de tr√°s de outro caminh√£o (um caminh√£o-tanque de cor escura, que est√° √† frente do caminh√£o que filma) e avan√ßa para a contram√£o para tentar ultrapassar ambos os caminh√µes.

No momento em que o ve√≠culo branco est√° na contram√£o, se aproximando da lateral do caminh√£o que filma e j√° tendo ultrapassado o caminh√£o-tanque, um **ve√≠culo vindo em sentido contr√°rio** (um carro de cor clara, possivelmente um SUV ou hatch) aparece na pista.

Sem espa√ßo para completar a ultrapassagem e com o ve√≠culo vindo na dire√ß√£o oposta, o carro branco √© for√ßado a "cortar" bruscamente e se espremer entre o caminh√£o que filma e o caminh√£o-tanque que ele havia acabado de ultrapassar. A manobra √© extremamente perigosa, com o carro branco ficando a cent√≠metros de colidir com a lateral do caminh√£o que filma e o ve√≠culo que vinha na contram√£o. Ele consegue se encaixar na faixa de rolamento por pouco, evitando uma colis√£o frontal com o ve√≠culo que se aproximava e uma poss√≠vel colis√£o lateral com o caminh√£o que o filmava.

**Legalidade da Manobra:**

A ultrapassagem realizada pelo ve√≠culo branco foi **flagrantemente ilegal e extremamente perigosa** por v√°rios motivos:
1.  **Faixa Dupla Cont√≠nua Amarela:** Pro√≠be expressamente a ultrapassagem para ambos os sentidos de tr√°fego.
2.  **Curva:** Ultrapassagens em curvas s√£o proibidas devido √† visibilidade reduzida e ao alto risco de colis√£o frontal.
3.  **Presen√ßa de Ve√≠culo em Sentido Cont√°rio:** O condutor n√£o avaliou a presen√ßa de tr√°fego no sentido oposto antes de iniciar a manobra, colocando-se e a terceiros em risco iminente.
4.  **Condi√ß√µes Clim√°ticas/Visibilidade:** A pista molhada e a prov√°vel chuva reduzem a ader√™ncia dos pneus e a visibilidade, tornando manobras arriscadas ainda mais perigosas.

**Ve√≠culos Identificados:**

*   **Ve√≠culo que realiza a ultrapassagem (sedan branco):**
    *   **Placa:** PCF 9041
    *   **Modelo:** Toyota Corolla (gera√ß√£o que circulou aproximadamente entre 2008 e 2014, conhecido como "Brad Pitt" no Brasil, ou a gera√ß√£o imediatamente anterior ao modelo que come√ßou a ter LEDs nos far√≥is traseiros)

*   **Caminh√£o que grava o v√≠deo:**
    *   **Placa:** N√£o vis√≠vel (somente a parte superior do ba√∫/carroceria).
    *   **Modelo:** N√£o √© poss√≠vel determinar o modelo exato do caminh√£o, mas o ba√∫/carroceria traseira possui uma marca√ß√£o com o site **"www.igr.com.br"**, sugerindo ser um ve√≠culo da empresa IGR Transportes.

*   **Caminh√£o-tanque sendo ultrapassado:**
    *   **Placa:** N√£o vis√≠vel.
    *   **Modelo:** N√£o √© poss√≠vel determinar o modelo ou marca, apenas que √© um caminh√£o-tanque de cor escura.
    """

def interpretar_com_gpt(gemini_text: str, mock: bool = True) -> str:
    if not mock:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        prompt = (
            "A seguir est√° uma descri√ß√£o textual de uma cena de tr√¢nsito analisada por IA:\n\n"
            f"{gemini_text}\n\n"
            "Com base nessa descri√ß√£o, extraia apenas informa√ß√µes relacionadas a ve√≠culos identific√°veis, estruturando da seguinte forma em um json que possua v√°rias poss√≠veis infra√ß√µes (uma lista):\n\n"
            "- Placa:\n"
            "- Modelo:\n"
            "- Cor:\n"
            "- Comportamento observado:\n"
            "- Poss√≠vel infra√ß√£o: (sim/n√£o)\n\n"
            "Se houver m√∫ltiplos ve√≠culos, repita essa estrutura apenas para ve√≠culos que possuem poss√≠veis infra√ß√µes."
            "Me retorne APENAS o a lista com os elementos json dentro, SEM os caracteres de markdown, e com as chaves dos itens EXATAMENTE como estao escritas acima, pois estou integrando a sa√≠da diretamente em minha API!!!"
        )

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Voc√™ √© um assistente que identifica poss√≠veis infra√ß√µes de tr√¢nsito a partir de descri√ß√µes de v√≠deos."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )

        json_response = get_json_from_string(response.choices[0].message.content.strip())

    else:
        print("Entrou no mock")
        resposta_mock = """"
            [ { "Placa": "PCF 9041", "Modelo": "Toyota Corolla (gera√ß√£o 2014-2019)", "Cor": "Prata", "Comportamento observado": "Tentativa de ultrapassagem em local proibido com faixa dupla cont√≠nua, invadindo a faixa de sentido contr√°rio e realizando manobra evasiva perigosa.", "Poss√≠vel infra√ß√£o": "sim" } ]
        """

        json_response = get_json_from_string(resposta_mock)

    print("****************************************")
    print("Resposta do GPT: \n")
    print(json_response)
    print("****************************************")

    return json_response

def add_law_references(structured_output: list, pre_law_references: list = []) -> tuple[bool, list]:
    """Add law references to the structured output based on the infractions detected via RAG."""
    
    for idx, item in enumerate(structured_output):
        print(item['Comportamento observado'])
        nodes = query_db(
            query=item['Comportamento observado'],
            index_name="codigo-transito-brasileiro",
            k=10
        )
        
        similar_nodes =  [node for node in nodes if node['score'] > 0.6]
        
        
        if item['Poss√≠vel infra√ß√£o'].lower() == "sim":

            
            # if you have pre_law_references and the query still returns no nodes, assumes there are no infractions and the model hallucinated
            if len(pre_law_references) > 0 and len(similar_nodes) == 0:
                return [], None

            print(structured_output)

            law_references = []
            for node in similar_nodes:
                law_reference = {
                    'law_reference': node['path'],
                    'ticket': law_descriptions[node['path']],
                    'score': node['score']
                }
                law_references.append(law_reference)
            
            print(similar_nodes)
            print(law_references)
            
            structured_output[idx]['law_references'] = law_references
            
            return [], structured_output
            
        elif len(similar_nodes) > 0:
            law_references_to_return = [node['path'] for node in similar_nodes]
            return law_references_to_return, None
        
            

    